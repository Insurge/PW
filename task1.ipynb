{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Комп'ютерний практикум №1: Метод кореляційного аналізу даних\n",
    "\n",
    "**Дисципліна:** Інтелектуальний аналіз даних  \n",
    "**Тема:** Кореляційний аналіз  \n",
    "**Виконав:** [ПІБ студента]  \n",
    "**Група:** [Номер групи]  \n",
    "**Викладач:** [ПІБ викладача]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Параметри та налаштування\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметри аналізу\n",
    "user_data_path = None  # або 'path/to/data.csv'\n",
    "alpha = 0.05  # рівень значущості\n",
    "random_state = 42  # для відтворюваності результатів\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Імпорт бібліотек\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, kstest, pearsonr, spearmanr\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Встановлення seed для відтворюваності\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Створення папки для результатів\n",
    "output_dir = Path('outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"[OK] Всі бібліотеки успішно імпортовано\")\n",
    "print(f\"[OK] Папка для результатів: {output_dir.absolute()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Мета роботи\n",
    "\n",
    "Оволодіння методами кореляційного аналізу для дослідження статистичних зв'язків між змінними, визначення сили та напрямку зв'язку, перевірки статистичної значущості кореляційних коефіцієнтів.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Завдання\n",
    "\n",
    "1. Оволодіти методами кореляційного аналізу (коефіцієнти Пірсона та Спірмена).\n",
    "2. Виконати кореляційний аналіз між змінними, визначити силу та напрямок зв'язку, перевірити статистичну значущість.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Генерація або завантаження даних\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=200, missing_rate=0.07):\n",
    "    \"\"\"\n",
    "    Генерація синтетичних даних з правдоподібними кореляціями\n",
    "    \n",
    "    Очікувані зв'язки:\n",
    "    - sleep_hours ↗ productivity_score (помірно позитивна)\n",
    "    - steps_per_day ↘ weight_kg (слабко/помірно негативна)\n",
    "    - calories_intake ↗ weight_kg (позитивна)\n",
    "    - caffeine_mg ↗ productivity_score (слабко позитивна)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Базові незалежні змінні\n",
    "    sleep_hours = np.random.normal(7, 1.2, n_samples)\n",
    "    sleep_hours = np.clip(sleep_hours, 4, 10)\n",
    "    \n",
    "    steps_per_day = np.random.normal(8000, 2500, n_samples)\n",
    "    steps_per_day = np.clip(steps_per_day, 2000, 15000)\n",
    "    \n",
    "    caffeine_mg = np.random.normal(150, 80, n_samples)\n",
    "    caffeine_mg = np.clip(caffeine_mg, 0, 400)\n",
    "    \n",
    "    calories_intake = np.random.normal(2000, 400, n_samples)\n",
    "    calories_intake = np.clip(calories_intake, 1200, 3500)\n",
    "    \n",
    "    # Залежні змінні з кореляціями\n",
    "    # productivity_score: залежить від сну (+) та кофеїну (+)\n",
    "    productivity_score = (\n",
    "        30 + \n",
    "        6 * sleep_hours +  # помірна позитивна кореляція\n",
    "        0.03 * caffeine_mg +  # слабка позитивна кореляція\n",
    "        np.random.normal(0, 8, n_samples)\n",
    "    )\n",
    "    productivity_score = np.clip(productivity_score, 0, 100)\n",
    "    \n",
    "    # weight_kg: залежить від калорій (+) та кроків (-)\n",
    "    weight_kg = (\n",
    "        40 + \n",
    "        0.012 * calories_intake +  # позитивна кореляція\n",
    "        -0.0015 * steps_per_day +  # негативна кореляція\n",
    "        np.random.normal(0, 5, n_samples)\n",
    "    )\n",
    "    weight_kg = np.clip(weight_kg, 50, 100)\n",
    "    \n",
    "    # Створення DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'sleep_hours': sleep_hours,\n",
    "        'productivity_score': productivity_score,\n",
    "        'steps_per_day': steps_per_day,\n",
    "        'calories_intake': calories_intake,\n",
    "        'weight_kg': weight_kg,\n",
    "        'caffeine_mg': caffeine_mg\n",
    "    })\n",
    "    \n",
    "    # Додавання пропусків (5-10%)\n",
    "    n_missing = int(n_samples * len(df.columns) * missing_rate)\n",
    "    missing_indices = np.random.choice(\n",
    "        n_samples * len(df.columns), \n",
    "        size=n_missing, \n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    for idx in missing_indices:\n",
    "        row = idx // len(df.columns)\n",
    "        col = idx % len(df.columns)\n",
    "        df.iloc[row, col] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Завантаження або генерація даних\n",
    "if user_data_path is not None:\n",
    "    print(f\"Завантаження даних з файлу: {user_data_path}\")\n",
    "    df = pd.read_csv(user_data_path)\n",
    "    print(\"[OK] Дані завантажено з CSV\")\n",
    "else:\n",
    "    print(\"Генерація синтетичних даних...\")\n",
    "    df = generate_synthetic_data(n_samples=200, missing_rate=0.07)\n",
    "    \n",
    "    # Збереження синтетичних даних\n",
    "    synthetic_path = output_dir / 'synthetic_data.csv'\n",
    "    df.to_csv(synthetic_path, index=False)\n",
    "    print(f\"[OK] Синтетичні дані збережено: {synthetic_path}\")\n",
    "\n",
    "print(f\"\\nРозмір датасету: {df.shape[0]} рядків x {df.shape[1]} стовпців\")\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ІНФОРМАЦІЯ ПРО ДАТАСЕТ\")\n",
    "print(\"=\" * 60)\n",
    "df.info()\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Описова статистика\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ОПИСОВА СТАТИСТИКА\")\n",
    "print(\"=\" * 60)\n",
    "df.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Аналіз пропущених значень\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Розрахунок пропусків\n",
    "missing_data = pd.DataFrame({\n",
    "    'Змінна': df.columns,\n",
    "    'Пропусків': df.isnull().sum(),\n",
    "    'Частка (%)': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"АНАЛІЗ ПРОПУЩЕНИХ ЗНАЧЕНЬ\")\n",
    "print(\"=\" * 60)\n",
    "print(missing_data.to_string(index=False))\n",
    "print(\"\\nЗагальна частка пропусків: {:.2f}%\".format(\n",
    "    df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100\n",
    "))\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Обробка пропусків: два підходи\n",
    "\n",
    "**Підхід A (Pairwise):** Попарне виключення - використовуємо всі доступні дані для кожної пари змінних.\n",
    "\n",
    "**Підхід B (Listwise):** Повне виключення - видаляємо всі рядки з будь-якими пропусками.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Підхід A: Pairwise (оригінальні дані з пропусками)\n",
    "df_pairwise = df.copy()\n",
    "\n",
    "# Підхід B: Listwise (видалення рядків з пропусками)\n",
    "df_listwise = df.dropna()\n",
    "\n",
    "print(\"ПОРІВНЯННЯ ПІДХОДІВ ДО ОБРОБКИ ПРОПУСКІВ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Оригінальний датасет: {len(df)} спостережень\")\n",
    "print(f\"Після pairwise: {len(df_pairwise)} спостережень (без змін)\")\n",
    "print(f\"Після listwise: {len(df_listwise)} спостережень (-{len(df) - len(df_listwise)} рядків)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Перевірка нормальності розподілу\n",
    "\n",
    "### 7.1. Функція для тестування нормальності\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normality(data, var_name, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Перевірка нормальності розподілу змінної\n",
    "    \n",
    "    Використовує:\n",
    "    - Shapiro-Wilk тест (якщо n ≤ 5000)\n",
    "    - Kolmogorov-Smirnov тест (якщо n > 5000)\n",
    "    \n",
    "    H0: дані мають нормальний розподіл\n",
    "    H1: дані не мають нормального розподілу\n",
    "    \"\"\"\n",
    "    # Видалення пропусків\n",
    "    clean_data = data.dropna()\n",
    "    n = len(clean_data)\n",
    "    \n",
    "    if n == 0:\n",
    "        return {\n",
    "            'variable': var_name,\n",
    "            'test': 'N/A',\n",
    "            'statistic': np.nan,\n",
    "            'p_value': np.nan,\n",
    "            'n': 0,\n",
    "            'normality_conclusion': 'Недостатньо даних'\n",
    "        }\n",
    "    \n",
    "    # Вибір тесту\n",
    "    if n <= 5000:\n",
    "        test_name = 'Shapiro-Wilk'\n",
    "        statistic, p_value = shapiro(clean_data)\n",
    "    else:\n",
    "        test_name = 'Kolmogorov-Smirnov'\n",
    "        # KS тест проти нормального розподілу з параметрами вибірки\n",
    "        mean, std = clean_data.mean(), clean_data.std()\n",
    "        statistic, p_value = kstest(clean_data, lambda x: stats.norm.cdf(x, mean, std))\n",
    "    \n",
    "    # Висновок\n",
    "    if p_value >= alpha:\n",
    "        conclusion = f'Нормальний (p={p_value:.4f} ≥ {alpha})'\n",
    "        is_normal = True\n",
    "    else:\n",
    "        conclusion = f'Не нормальний (p={p_value:.4f} < {alpha})'\n",
    "        is_normal = False\n",
    "    \n",
    "    return {\n",
    "        'variable': var_name,\n",
    "        'test': test_name,\n",
    "        'statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "        'n': n,\n",
    "        'normality_conclusion': conclusion,\n",
    "        'is_normal': is_normal\n",
    "    }\n",
    "\n",
    "print(\"[OK] Функція тестування нормальності створена\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестування для listwise підходу\n",
    "normality_results = []\n",
    "\n",
    "for col in df_listwise.select_dtypes(include=[np.number]).columns:\n",
    "    result = test_normality(df_listwise[col], col, alpha)\n",
    "    normality_results.append(result)\n",
    "\n",
    "# Створення таблиці результатів\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "normality_df_display = normality_df[['variable', 'test', 'statistic', 'p_value', 'n', 'normality_conclusion']]\n",
    "\n",
    "# Збереження результатів\n",
    "normality_path = output_dir / 'normality_summary.csv'\n",
    "normality_df_display.to_csv(normality_path, index=False)\n",
    "\n",
    "print(\"РЕЗУЛЬТАТИ ТЕСТІВ НОРМАЛЬНОСТІ\")\n",
    "print(\"=\" * 80)\n",
    "print(normality_df_display.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"[OK] Результати збережено: {normality_path}\")\n",
    "\n",
    "# Створення словника для швидкого доступу\n",
    "normality_dict = {row['variable']: row['is_normal'] for _, row in normality_df.iterrows()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Вибір методу кореляції та інтерпретація\n",
    "\n",
    "### 8.1. Методика вибору коефіцієнта кореляції\n",
    "\n",
    "**Правила вибору:**\n",
    "- Якщо обидві змінні мають нормальний розподіл → **Коефіцієнт Пірсона** (параметричний)\n",
    "- Якщо хоча б одна змінна не має нормального розподілу → **Коефіцієнт Спірмена** (непараметричний, ранговий)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_strength(r):\n",
    "    \"\"\"\n",
    "    Інтерпретація сили зв'язку за шкалою з методички\n",
    "    \n",
    "    Шкала:\n",
    "    0.75-1.00: дуже високий\n",
    "    0.50-0.74: високий\n",
    "    0.25-0.49: середній\n",
    "    0.00-0.24: слабкий\n",
    "    \"\"\"\n",
    "    abs_r = abs(r)\n",
    "    direction = \"позитивний\" if r >= 0 else \"негативний\"\n",
    "    \n",
    "    if abs_r >= 0.75:\n",
    "        strength = \"дуже високий\"\n",
    "    elif abs_r >= 0.50:\n",
    "        strength = \"високий\"\n",
    "    elif abs_r >= 0.25:\n",
    "        strength = \"середній\"\n",
    "    else:\n",
    "        strength = \"слабкий\"\n",
    "    \n",
    "    return f\"{strength} {direction}\"\n",
    "\n",
    "\n",
    "def choose_correlation_method(x, y, var_x, var_y, normality_dict):\n",
    "    \"\"\"\n",
    "    Вибір методу кореляції на основі нормальності змінних\n",
    "    \n",
    "    Повертає: method, coefficient, p_value, n\n",
    "    \"\"\"\n",
    "    # Видалення пропусків для пари\n",
    "    mask = ~(pd.isna(x) | pd.isna(y))\n",
    "    x_clean = x[mask]\n",
    "    y_clean = y[mask]\n",
    "    n = len(x_clean)\n",
    "    \n",
    "    if n < 3:\n",
    "        return 'N/A', np.nan, np.nan, n\n",
    "    \n",
    "    # Перевірка нормальності\n",
    "    x_normal = normality_dict.get(var_x, False)\n",
    "    y_normal = normality_dict.get(var_y, False)\n",
    "    \n",
    "    # Вибір методу\n",
    "    if x_normal and y_normal:\n",
    "        method = 'Pearson'\n",
    "        coef, p_val = pearsonr(x_clean, y_clean)\n",
    "    else:\n",
    "        method = 'Spearman'\n",
    "        coef, p_val = spearmanr(x_clean, y_clean)\n",
    "    \n",
    "    return method, coef, p_val, n\n",
    "\n",
    "print(\"[OK] Функції вибору методу та інтерпретації створено\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Розрахунок кореляцій\n",
    "\n",
    "### 9.1. Функція для обчислення всіх кореляцій\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_correlations(df, normality_dict, approach_name, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Обчислення кореляцій для всіх пар змінних\n",
    "    \n",
    "    Параметри:\n",
    "    - df: DataFrame з даними\n",
    "    - normality_dict: словник з результатами тестів нормальності\n",
    "    - approach_name: 'pairwise' або 'listwise'\n",
    "    - alpha: рівень значущості\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    for i, var_x in enumerate(numeric_cols):\n",
    "        for var_y in numeric_cols[i+1:]:\n",
    "            method, coef, p_val, n = choose_correlation_method(\n",
    "                df[var_x], df[var_y], var_x, var_y, normality_dict\n",
    "            )\n",
    "            \n",
    "            if not np.isnan(coef):\n",
    "                # Визначення значущості\n",
    "                if p_val < 0.01:\n",
    "                    significance = '**'\n",
    "                elif p_val < alpha:\n",
    "                    significance = '*'\n",
    "                else:\n",
    "                    significance = ''\n",
    "                \n",
    "                # Висновок про гіпотезу\n",
    "                h0_conclusion = 'Відхилено' if p_val < alpha else 'Не відхилено'\n",
    "                \n",
    "                results.append({\n",
    "                    'variable_x': var_x,\n",
    "                    'variable_y': var_y,\n",
    "                    'method': method,\n",
    "                    'coefficient': coef,\n",
    "                    'p_value': p_val,\n",
    "                    'n': n,\n",
    "                    'significance': significance,\n",
    "                    'strength_label': interpret_strength(coef),\n",
    "                    'H0_conclusion': h0_conclusion,\n",
    "                    'approach': approach_name\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"[OK] Функція обчислення кореляцій створена\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Обчислення кореляцій для обох підходів\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Підхід A: Pairwise\n",
    "print(\"Обчислення кореляцій (Pairwise)...\")\n",
    "corr_pairwise = calculate_all_correlations(df_pairwise, normality_dict, 'pairwise', alpha)\n",
    "corr_pairwise_path = output_dir / 'correlations_pairwise.csv'\n",
    "corr_pairwise.to_csv(corr_pairwise_path, index=False)\n",
    "print(f\"[OK] Збережено: {corr_pairwise_path}\")\n",
    "\n",
    "# Підхід B: Listwise\n",
    "print(\"Обчислення кореляцій (Listwise)...\")\n",
    "corr_listwise = calculate_all_correlations(df_listwise, normality_dict, 'listwise', alpha)\n",
    "corr_listwise_path = output_dir / 'correlations_listwise.csv'\n",
    "corr_listwise.to_csv(corr_listwise_path, index=False)\n",
    "print(f\"[OK] Збережено: {corr_listwise_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"РЕЗУЛЬТАТИ КОРЕЛЯЦІЙНОГО АНАЛІЗУ (PAIRWISE)\")\n",
    "print(\"=\" * 100)\n",
    "display_cols = ['variable_x', 'variable_y', 'method', 'coefficient', 'p_value', 'n', 'significance', 'strength_label']\n",
    "print(corr_pairwise[display_cols].to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. Таблиця кореляцій у стилі SPSS для основної пари\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вибираємо основну пару: sleep_hours vs productivity_score\n",
    "main_pair = corr_listwise[\n",
    "    (corr_listwise['variable_x'] == 'sleep_hours') & \n",
    "    (corr_listwise['variable_y'] == 'productivity_score')\n",
    "]\n",
    "\n",
    "if len(main_pair) > 0:\n",
    "    row = main_pair.iloc[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ТАБЛИЦЯ КОРЕЛЯЦІЙ (СТИЛЬ SPSS)\")\n",
    "    print(\"Основна пара: sleep_hours ↔ productivity_score\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nМетод: {row['method']}\")\n",
    "    print(f\"Коефіцієнт кореляції (r): {row['coefficient']:.4f}{row['significance']}\")\n",
    "    print(f\"P-значення (двостороннє): {row['p_value']:.4f}\")\n",
    "    print(f\"Кількість спостережень (N): {row['n']}\")\n",
    "    print(f\"Інтерпретація: {row['strength_label']}\")\n",
    "    print(f\"\\nПримітки:\")\n",
    "    print(f\"  * Кореляція значуща на рівні 0.05 (двостороння)\")\n",
    "    print(f\"  ** Кореляція значуща на рівні 0.01 (двостороння)\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"Основна пара не знайдена в результатах\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Візуалізація результатів\n",
    "\n",
    "### 10.1. Діаграми розсіювання для ключових пар\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter_plot(df, x_var, y_var, method, r, p_val, n, output_path):\n",
    "    \"\"\"\n",
    "    Створення діаграми розсіювання з лінією регресії (для Пірсона)\n",
    "    \"\"\"\n",
    "    # Очищення даних\n",
    "    mask = ~(pd.isna(df[x_var]) | pd.isna(df[y_var]))\n",
    "    x_clean = df[x_var][mask]\n",
    "    y_clean = df[y_var][mask]\n",
    "    \n",
    "    # Створення графіка\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x_clean, y_clean)\n",
    "    \n",
    "    # Лінія регресії тільки для Пірсона\n",
    "    if method == 'Pearson':\n",
    "        z = np.polyfit(x_clean, y_clean, 1)\n",
    "        p = np.poly1d(z)\n",
    "        plt.plot(x_clean, p(x_clean), linestyle='--')\n",
    "    \n",
    "    plt.xlabel(x_var.replace('_', ' ').title())\n",
    "    plt.ylabel(y_var.replace('_', ' ').title())\n",
    "    plt.title(f'{x_var} vs {y_var}\n",
    "{method}: r={r:.3f}, p={p_val:.4f}, n={n}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Вибір 4 цікавих пар для візуалізації\n",
    "pairs_to_plot = [\n",
    "    ('sleep_hours', 'productivity_score'),\n",
    "    ('steps_per_day', 'weight_kg'),\n",
    "    ('calories_intake', 'weight_kg'),\n",
    "    ('caffeine_mg', 'productivity_score')\n",
    "]\n",
    "\n",
    "scatter_plots = []\n",
    "\n",
    "print(\"Створення діаграм розсіювання...\n",
    "\")\n",
    "for x_var, y_var in pairs_to_plot:\n",
    "    # Знаходимо результати для цієї пари\n",
    "    pair_result = corr_listwise[\n",
    "        ((corr_listwise['variable_x'] == x_var) & (corr_listwise['variable_y'] == y_var)) |\n",
    "        ((corr_listwise['variable_x'] == y_var) & (corr_listwise['variable_y'] == x_var))\n",
    "    ]\n",
    "    \n",
    "    if len(pair_result) > 0:\n",
    "        row = pair_result.iloc[0]\n",
    "        output_path = output_dir / f'scatter_{x_var}_vs_{y_var}.png'\n",
    "        create_scatter_plot(\n",
    "            df_listwise, x_var, y_var, \n",
    "            row['method'], row['coefficient'], row['p_value'], row['n'],\n",
    "            output_path\n",
    "        )\n",
    "        scatter_plots.append(output_path)\n",
    "        print(f\"[OK] {output_path.name}\")\n",
    "\n",
    "print(f\"\n",
    "[OK] Створено {len(scatter_plots)} діаграм розсіювання\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Матриця кореляцій\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Створення матриці кореляцій Пірсона для візуалізації\n",
    "corr_matrix = df_listwise.corr(method='pearson')\n",
    "\n",
    "# Візуалізація через matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "\n",
    "# Налаштування осей\n",
    "ax.set_xticks(np.arange(len(corr_matrix.columns)))\n",
    "ax.set_yticks(np.arange(len(corr_matrix.columns)))\n",
    "ax.set_xticklabels(corr_matrix.columns, rotation=45, ha='right')\n",
    "ax.set_yticklabels(corr_matrix.columns)\n",
    "\n",
    "# Додавання значень кореляцій\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(len(corr_matrix.columns)):\n",
    "        text = ax.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
    "                      ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Коефіцієнт кореляції', rotation=270, labelpad=20)\n",
    "\n",
    "plt.title('Матриця кореляцій (Pearson, listwise)', pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Збереження\n",
    "matrix_path = output_dir / 'correlation_matrix.png'\n",
    "plt.savefig(matrix_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"[OK] Матриця кореляцій збережена: {matrix_path.name}\")\n",
    "\n",
    "# Також збережемо як CSV\n",
    "matrix_csv_path = output_dir / 'correlation_matrix.csv'\n",
    "corr_matrix.to_csv(matrix_csv_path)\n",
    "print(f\"[OK] Матриця кореляцій (CSV): {matrix_csv_path.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Висновок по основній парі змінних\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формування висновку для основної пари\n",
    "if len(main_pair) > 0:\n",
    "    row = main_pair.iloc[0]\n",
    "    \n",
    "    conclusion_text = f\"\"\"\n",
    "ВИСНОВОК ПО ОСНОВНІЙ ПАРІ ЗМІННИХ\n",
    "{'=' * 80}\n",
    "\n",
    "Змінні: {row['variable_x']} ↔ {row['variable_y']}\n",
    "\n",
    "Результати аналізу:\n",
    "  • Метод: {row['method']} (обрано на основі тестів нормальності)\n",
    "  • Коефіцієнт кореляції: r = {row['coefficient']:.4f}\n",
    "  • P-значення: p = {row['p_value']:.4f}\n",
    "  • Кількість спостережень: n = {row['n']}\n",
    "  • Сила зв'язку: {row['strength_label']}\n",
    "\n",
    "Статистичний висновок:\n",
    "На рівні значущості α = {alpha}, гіпотезу H₀: ρ = 0 (відсутність кореляції) \n",
    "{'ВІДХИЛЕНО' if row['p_value'] < alpha else 'НЕ ВІДХИЛЕНО'}.\n",
    "\n",
    "Інтерпретація:\n",
    "Було виявлено {row['strength_label']} зв'язок між кількістю годин сну та \n",
    "показником продуктивності (r = {row['coefficient']:.4f}, p = {row['p_value']:.4f}, n = {row['n']}).\n",
    "\n",
    "{'Це означає, що зі збільшенням тривалості сну спостерігається тенденція до' if row['coefficient'] > 0 else 'Це означає, що зі збільшенням тривалості сну спостерігається тенденція до зниження'}\n",
    "{'підвищення' if row['coefficient'] > 0 else ''} продуктивності. Зв'язок є статистично значущим,\n",
    "що свідчить про наявність реальної асоціації між цими змінними в досліджуваній\n",
    "популяції.\n",
    "\n",
    "{'=' * 80}\n",
    "\"\"\"\n",
    "    \n",
    "    print(conclusion_text)\n",
    "    \n",
    "    # Збереження висновку\n",
    "    conclusion_path = output_dir / 'main_pair_conclusion.txt'\n",
    "    with open(conclusion_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(conclusion_text)\n",
    "    \n",
    "    print(f\"\n",
    "[OK] Висновок збережено: {conclusion_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Автоматична генерація звіту\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_report():\n",
    "    \"\"\"Генерація markdown звіту згідно з вимогами методички\"\"\"\n",
    "    \n",
    "    report = f\"\"\"# Звіт про виконання комп'ютерного практикуму №1\n",
    "## Метод кореляційного аналізу даних\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ВСТУПНА ЧАСТИНА\n",
    "\n",
    "**ВНЗ:** [Назва навчального закладу]  \n",
    "**Кафедра:** [Назва кафедри]  \n",
    "**Дисципліна:** Інтелектуальний аналіз даних  \n",
    "**№ роботи:** 1  \n",
    "**Тема:** Метод кореляційного аналізу даних  \n",
    "**Група:** [Номер групи]  \n",
    "**Виконав:** [ПІБ студента]  \n",
    "**Викладач:** [ПІБ викладача]  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. МЕТА РОБОТИ\n",
    "\n",
    "Оволодіння методами кореляційного аналізу для дослідження статистичних зв'язків між змінними, визначення сили та напрямку зв'язку, перевірки статистичної значущості кореляційних коефіцієнтів.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. ЗАВДАННЯ\n",
    "\n",
    "1. Оволодіти методами кореляційного аналізу (коефіцієнти Пірсона та Спірмена).\n",
    "2. Виконати кореляційний аналіз між змінними, визначити силу та напрямок зв'язку, перевірити статистичну значущість.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. МЕТОДИКА\n",
    "\n",
    "### 4.1. Вибір методу кореляції\n",
    "\n",
    "Для кожної пари змінних метод кореляції обирався за наступними правилами:\n",
    "\n",
    "- **Коефіцієнт Пірсона** (параметричний): якщо обидві змінні мають нормальний розподіл\n",
    "- **Коефіцієнт Спірмена** (непараметричний, ранговий): якщо хоча б одна змінна не має нормального розподілу\n",
    "\n",
    "### 4.2. Перевірка нормальності\n",
    "\n",
    "Для перевірки нормальності розподілу використовувався:\n",
    "- **Тест Shapiro-Wilk** (для вибірок n ≤ 5000)\n",
    "- **Тест Kolmogorov-Smirnov** (для вибірок n > 5000)\n",
    "\n",
    "Гіпотеза H₀: дані мають нормальний розподіл.  \n",
    "Рівень значущості: α = {alpha}\n",
    "\n",
    "### 4.3. Обробка пропущених значень\n",
    "\n",
    "Використано два підходи:\n",
    "\n",
    "- **Підхід A (Pairwise deletion):** Попарне виключення\n",
    "- **Підхід B (Listwise deletion):** Повне виключення\n",
    "\n",
    "### 4.4. Інтерпретація сили зв'язку\n",
    "\n",
    "| |r| | Інтерпретація |\n",
    "|------|---------------|\n",
    "| 0.75-1.00 | Дуже високий |\n",
    "| 0.50-0.74 | Високий |\n",
    "| 0.25-0.49 | Середній |\n",
    "| 0.00-0.24 | Слабкий |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. РЕЗУЛЬТАТИ\n",
    "\n",
    "### 5.1. Характеристика даних\n",
    "\n",
    "- **Кількість спостережень (pairwise):** {len(df_pairwise)}\n",
    "- **Кількість спостережень (listwise):** {len(df_listwise)}\n",
    "- **Кількість змінних:** {len(df.columns)}\n",
    "- **Змінні:** {', '.join(df.columns.tolist())}\n",
    "\n",
    "### 5.2. Результати кореляційного аналізу\n",
    "\n",
    "#### Топ-5 найсильніших кореляцій (Listwise):\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Додаємо топ кореляції\n",
    "    top_corr = corr_listwise.nlargest(5, 'coefficient', keep='all')[['variable_x', 'variable_y', 'method', 'coefficient', 'p_value', 'strength_label']]\n",
    "    report += \"\\n\" + top_corr.to_string(index=False) + \"\\n\\n\"\n",
    "    \n",
    "    report += f\"\"\"Повні результати збережено у файлах:\n",
    "- `correlations_pairwise.csv`\n",
    "- `correlations_listwise.csv`\n",
    "\n",
    "### 5.3. Візуалізації\n",
    "\n",
    "Створено наступні графіки:\n",
    "\n",
    "1. **Діаграми розсіювання**\n",
    "2. **Матриця кореляцій:** `correlation_matrix.png`\n",
    "\n",
    "---\n",
    "\n",
    "## 6. ВИСНОВКИ\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    if len(main_pair) > 0:\n",
    "        row = main_pair.iloc[0]\n",
    "        report += f\"\"\"1. **Основний результат:** Виявлено {row['strength_label']} зв'язок між {row['variable_x']} та {row['variable_y']} (r = {row['coefficient']:.4f}, p = {row['p_value']:.4f}).\n",
    "\n",
    "2. **Метод аналізу:** На основі тестів нормальності для аналізу використовувався коефіцієнт {row['method']}.\n",
    "\n",
    "3. **Статистична значущість:** Кореляція є {'статистично значущою' if row['p_value'] < alpha else 'статистично незначущою'} на рівні α = {alpha}.\n",
    "\n",
    "4. **Обробка пропусків:** Використано два підходи до обробки пропущених значень.\n",
    "\n",
    "5. **Практичне значення:** Отримані результати мають практичне значення для розуміння взаємозв'язків між змінними.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    report += \"\"\"---\n",
    "\n",
    "## 7. ВІДПОВІДІ НА КОНТРОЛЬНІ ЗАПИТАННЯ\n",
    "\n",
    "### 7.1. Які задачі вирішує кореляційний аналіз?\n",
    "\n",
    "- Визначення наявності статистичного зв'язку між змінними\n",
    "- Оцінка сили та напрямку зв'язку\n",
    "- Перевірка статистичної значущості виявлених зв'язків\n",
    "- Відбір змінних для регресійного аналізу\n",
    "- Виявлення мультиколінеарності\n",
    "\n",
    "### 7.2. Як знайти коефіцієнт кореляції?\n",
    "\n",
    "**Коефіцієнт Пірсона:** r = Σ[(xi - x̄)(yi - ȳ)] / √[Σ(xi - x̄)² x Σ(yi - ȳ)²]\n",
    "\n",
    "**Коефіцієнт Спірмена:** ρ = 1 - [6Σdi²] / [n(n² - 1)]\n",
    "\n",
    "### 7.3. Які типи коефіцієнтів кореляції існують?\n",
    "\n",
    "1. **Пірсона** - параметричний метод для лінійних зв'язків\n",
    "2. **Спірмена** - непараметричний ранговий метод\n",
    "3. **Кендалла** - непараметричний метод на основі конкордантності\n",
    "4. **Точковий бісеріальний** - для зв'язку безперервної та бінарної змінних\n",
    "5. **Фі-коефіцієнт** - для двох бінарних змінних\n",
    "\n",
    "### 7.4. Різниця між прямою та зворотною кореляцією?\n",
    "\n",
    "- **Пряма кореляція** (r > 0): Зі збільшенням однієї змінної збільшується інша\n",
    "- **Зворотна кореляція** (r < 0): Зі збільшенням однієї змінної зменшується інша\n",
    "- **Відсутність кореляції** (r ≈ 0): Змінні не пов'язані лінійно\n",
    "\n",
    "### 7.5. Як перевіряється значущість коефіцієнта кореляції?\n",
    "\n",
    "1. **Гіпотези:** H₀: ρ = 0 vs H₁: ρ ≠ 0\n",
    "2. **t-статистика:** t = r√(n-2) / √(1-r²)\n",
    "3. **Рішення:** Якщо p < α, відхиляємо H₀\n",
    "\n",
    "---\n",
    "\n",
    "## 8. СПИСОК ЗГЕНЕРОВАНИХ ФАЙЛІВ\n",
    "\n",
    "- `synthetic_data.csv`\n",
    "- `normality_summary.csv`\n",
    "- `correlations_pairwise.csv`\n",
    "- `correlations_listwise.csv`\n",
    "- `correlation_matrix.csv`\n",
    "- `correlation_matrix.png`\n",
    "- Діаграми розсіювання (4 файли)\n",
    "- `main_pair_conclusion.txt`\n",
    "- `report_draft.md`\n",
    "\n",
    "---\n",
    "\n",
    "**Дата виконання:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Генерація звіту\n",
    "report_content = generate_markdown_report()\n",
    "report_path = output_dir / 'report_draft.md'\n",
    "\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ЗВІТ УСПІШНО ЗГЕНЕРОВАНО\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"[OK] Збережено: {report_path}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Чек-лист згенерованих файлів\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ЧЕК-ЛИСТ ЗГЕНЕРОВАНИХ ФАЙЛІВ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "expected_files = [\n",
    "    'synthetic_data.csv',\n",
    "    'normality_summary.csv',\n",
    "    'correlations_pairwise.csv',\n",
    "    'correlations_listwise.csv',\n",
    "    'correlation_matrix.csv',\n",
    "    'correlation_matrix.png',\n",
    "    'scatter_sleep_hours_vs_productivity_score.png',\n",
    "    'scatter_steps_per_day_vs_weight_kg.png',\n",
    "    'scatter_calories_intake_vs_weight_kg.png',\n",
    "    'scatter_caffeine_mg_vs_productivity_score.png',\n",
    "    'main_pair_conclusion.txt',\n",
    "    'report_draft.md'\n",
    "]\n",
    "\n",
    "print(f\"\\nПапка: {output_dir.absolute()}\\n\")\n",
    "\n",
    "for i, filename in enumerate(expected_files, 1):\n",
    "    filepath = output_dir / filename\n",
    "    status = \"[OK]\" if filepath.exists() else \"[MISS]\"\n",
    "    size = filepath.stat().st_size if filepath.exists() else 0\n",
    "    size_kb = size / 1024\n",
    "    \n",
    "    print(f\"{i:2d}. {status} {filename:50s} ({size_kb:>8.2f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"АНАЛІЗ ЗАВЕРШЕНО УСПІШНО!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nВсього згенеровано {len([f for f in expected_files if (output_dir / f).exists()])} файлів\")\n",
    "print(f\"Повний звіт доступний у файлі: {output_dir / 'report_draft.md'}\")\n",
    "print(\"\\nДля перегляду результатів відкрийте папку 'outputs/'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
